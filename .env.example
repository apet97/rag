# Clockify RAG Environment Configuration
# Copy this file to .env and fill in your values

# ===================================
# API Server Configuration
# ===================================
ENV=dev
API_PORT=7001
API_HOST=0.0.0.0
API_TOKEN=change-me
DEBUG=false

# CORS Configuration (comma-separated list of allowed origins)
# Default: http://localhost:8080,http://127.0.0.1:8080
# IMPORTANT: Do not use wildcards (*) - always specify exact origins
# Example for production: https://example.com,https://app.example.com
CORS_ALLOWED_ORIGINS=http://localhost:8080,http://127.0.0.1:8080,http://localhost:7001

# ===================================
# LLM Configuration (NO API KEY NEEDED!)
# ===================================
# Your internal Ollama server
LLM_BASE_URL=http://10.127.0.192:11434

# Available model on your server (note the colon!)
LLM_MODEL=gpt-oss:20b

# Embedding model (HuggingFace format - no colons!)
# CRITICAL: Must match the model used when building the index!
# The index was built with intfloat/multilingual-e5-base (768 dimensions)
EMBEDDING_MODEL=intfloat/multilingual-e5-base

# LLM timeout and retry settings
LLM_TIMEOUT_SECONDS=30
LLM_RETRIES=3
LLM_BACKOFF=0.75

# Streaming support (requires Ollama with streaming enabled)
STREAMING_ENABLED=false

# ===================================
# Harmony Chat Format (for gpt-oss:20b optimal performance)
# ===================================
# IMPORTANT: gpt-oss:20b was post-trained to expect Harmony chat format.
# Without Harmony, responses degrade significantly. Always keep enabled for oss models.
#
# Use Harmony encoding: true=auto-detect for gpt-oss*, false=disable, auto=default behavior
# - true: Force enable Harmony (recommended for gpt-oss:20b models)
# - false: Disable Harmony (for standard OpenAI models)
# - auto: Auto-detect based on model name (default, detects gpt-oss* variants)
LLM_USE_HARMONY=auto

# API type for Harmony: "ollama" (Ollama with vLLM) or "openai" (OpenAI-compatible)
LLM_API_TYPE=ollama

# LLM temperature (default 0.0 for deterministic RAG responses)
# Recommended: 0.0-0.2 for RAG (minimize hallucination)
LLM_TEMPERATURE=0.0

# Circuit Breaker Configuration (fault tolerance for LLM calls)
LLM_CIRCUIT_BREAKER_THRESHOLD=5      # Consecutive failures before opening circuit
LLM_CIRCUIT_BREAKER_TIMEOUT=60       # Recovery timeout in seconds
LLM_CIRCUIT_BREAKER_SUCCESS=2        # Consecutive successes needed to close circuit

# Alternative local setup:
# LLM_BASE_URL=http://localhost:11434

# ===================================
# Search Configuration
# ===================================
# Default number of results to return
RETRIEVAL_K=20

# Lexical vs Dense weighting for hybrid retrieval
# SEARCH_LEXICAL_WEIGHT = weight for BM25 (0..1). Vector weight = 1 - this value
# Default 0.35 -> 35% lexical (BM25), 65% dense
SEARCH_LEXICAL_WEIGHT=0.50

# Maximum cache size (number of queries)
CACHE_SIZE=1000

# Minimum query length (characters)
MIN_QUERY_LENGTH=2

# ===================================
# Data Paths
# ===================================
# Path to FAISS index
FAISS_INDEX_PATH=index/faiss/clockify_url/index.bin

# Path to FAISS metadata
FAISS_METADATA_PATH=index/faiss/clockify_url/meta.json

# Path to glossary (for query expansion)
GLOSSARY_PATH=clockify-help/pages/help__getting-started__clockify-glossary.md

# ===================================
# Performance Tuning
# ===================================
# Number of worker processes
MAX_WORKERS=4

# Batch size for embedding
BATCH_SIZE=32

# ===================================
# Logging
# ===================================
LOG_LEVEL=INFO
LOG_FILE=logs/api.log

# ===================================
# Session Management (Multi-Turn Conversations)
# ===================================
# Session time-to-live in seconds (time before inactive sessions are cleaned up)
# Default: 3600 (1 hour) - sessions expire after 1 hour of inactivity
SESSION_TTL_SECONDS=3600

# Maximum number of concurrent chat sessions to keep in memory
# Default: 1000 - when limit is reached, oldest session is removed
# Lower values save memory but may disconnect active users
SESSION_MAX_CONVERSATIONS=1000

# Maximum conversation history turns to include in LLM context (prevents token explosion)
# Default: 3 - includes the last 3 turns to maintain context without exceeding limits
SESSION_MAX_HISTORY_TURNS=3

# ===================================
# Phase 2: Full-Article Context & Intent Analysis
# ===================================
# Use full article text instead of truncated 1600-char chunks
# Default: true - LLM reads complete articles for better understanding
FULL_ARTICLE_CONTEXT=true

# Adaptive article count based on query intent
# Default: true - adjusts number of articles per intent type
ADAPTIVE_ARTICLE_COUNT=true

# Article count per intent type (when adaptive is enabled)
ARTICLE_COUNT_HOWTO=3          # How-to questions: focused, fewer articles
ARTICLE_COUNT_COMPARISON=5     # Comparisons: need more diverse sources
ARTICLE_COUNT_FACTUAL=4        # Factual questions: precise answers
ARTICLE_COUNT_DEFINITION=3     # Definitions: clear, focused
ARTICLE_COUNT_GENERAL=4        # General queries: balanced coverage

# Maximum article length in characters (safety limit to prevent context overflow)
# Default: 50000 - truncates very long articles
MAX_ARTICLE_LENGTH=50000

# Support ticket parsing
# Default: true - detects and parses support tickets automatically
ENABLE_TICKET_PARSING=true

# Display intent and keywords in UI
# Default: true - shows extracted metadata to user
DISPLAY_INTENT_METADATA=true

# ===================================
# v2 Corpus Ingestion & Policy
# ===================================
# Strict domain policy for ingestion/runtime
ALLOWLIST_PATH=codex/ALLOWLIST.txt
DENYLIST_PATH=codex/DENYLIST.txt

# Enriched corpus from Phase 2
ENRICHED_LINKS_JSON=codex/CRAWLED_LINKS_enriched.json

# Namespace controls (index under index/faiss/<namespace>)
# CRITICAL: NAMESPACES must match the actual directory name in index/faiss/
# The index is built as 'clockify_url', so use that exact name.
# Common error: Setting NAMESPACES=clockify will cause "No such file or directory" errors
# If you get namespace errors, run: ./FIX_NAMESPACES.sh
NAMESPACE=clockify
NAMESPACES=clockify_url

# Embedding configuration (single source of truth)
# EMBEDDING_MODEL already set above; ensure EMBEDDING_DIM matches your model
# intfloat/multilingual-e5-base uses 768 dimensions
EMBEDDING_DIM=768

# ===================================
# Chunking Ablation
# ===================================
# Strategies: url_level (one chunk per URL), h2_h3_blocks (H2/H3 sections + token packing)
CHUNK_STRATEGY=url_level
CHUNK_SIZE=1200
CHUNK_OVERLAP=200

# ===================================
# Development (Uncomment for development)
# ===================================
# DEBUG=true
# API_HOST=127.0.0.1
# LOG_LEVEL=DEBUG
# CACHE_SIZE=100
